{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "All data is preprocessed according to the following steps.\n",
    "1. Data is split in a training set of 80% of the data and a test set of 20% of the data.\n",
    "2. Missing feature data is imputed using the mean. Missing target data is inferred from other available metadata.\n",
    "3. Outliers are removed, data is normalized and centered. Target Y1 is binned per 10 listenings and target Y2 is binned per year.\n",
    "\n",
    "Next to feature set f1, which contains all features, two more feature sets are created with PCA dimensionality reduction. For feature set f2 PCA is applied per column name group, and for feature set f3 PCA is applied on the total of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/split/train.csv')\n",
    "\n",
    "# For both targets, a feature set is created\n",
    "df_y1 = df.copy().drop(columns=['release'])\n",
    "df_y2 = df.copy().drop(columns=['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_reader():\n",
    "    \"\"\"\n",
    "    Each feature has a first name, optionally a second name, a statistic and a number.\n",
    "    This class allows to group feautures according to these aspects or combinations of these aspects.\n",
    "    Each method produces a list of feature names or a list of lists of feature names.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv):\n",
    "        self.fts = pd.read_csv(csv, dtype={'n':\"string\"})\n",
    "        self.fts = self.fts.fillna('')\n",
    "\n",
    "    def format(self, select):\n",
    "        return select.apply(lambda x: '_'.join(x).replace('__', '_'), axis=1).tolist()\n",
    "\n",
    "    def all(self):\n",
    "        select = self.fts.copy()\n",
    "        return self.format(select)\n",
    "\n",
    "    def first(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['n']=='01']\n",
    "        return self.format(select)\n",
    "\n",
    "    def min(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='min']\n",
    "        return self.format(select)\n",
    "    \n",
    "    def max(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='max']\n",
    "        return self.format(select)\n",
    "\n",
    "    def median(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='median']\n",
    "        return self.format(select)\n",
    "\n",
    "    def mean(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='mean']\n",
    "        return self.format(select)\n",
    "    \n",
    "    def std(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='std']\n",
    "        return self.format(select)\n",
    "\n",
    "    def skew(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='skew']\n",
    "        return self.format(select)\n",
    "\n",
    "    def kurtosis(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='kurtosis']\n",
    "        return self.format(select)\n",
    "\n",
    "    def per_nns(self):\n",
    "        \"\"\"\n",
    "        List of lists per name1, name2, stat, per name1, name2.\n",
    "        \"\"\"\n",
    "        select = self.fts.copy()\n",
    "        select = [[self.format(grp2) for idx2, grp2 in grp.groupby(by=['stat'], sort=False)] for idx, grp in select.groupby(by=['name1', 'name2'])]\n",
    "        return select\n",
    "    \n",
    "    def per_sn(self):\n",
    "        \"\"\"\n",
    "        List of lists per stat, n. \n",
    "        \"\"\"\n",
    "        select = self.fts.copy()\n",
    "        select = [[self.format(grp2) for idx2, grp2 in grp.groupby(by=['n'], sort=False)] for idx, grp in select.groupby(by=['stat'], sort=False)]\n",
    "        return select\n",
    "\n",
    "fts = Feature_reader('features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1: Dropped 0 entries of 85259, 85259 entries left.\n"
     ]
    }
   ],
   "source": [
    "n_orig = df_y1.shape[0]\n",
    "n_na = df_y1['popularity'].isna().sum()\n",
    "df_y1 = df_y1.dropna(subset=['popularity'])\n",
    "print(f'y1: Dropped {n_na} entries of {n_orig}, {n_orig - n_na} entries left.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 28915 entries of 85259, 56344 entries left.\n"
     ]
    }
   ],
   "source": [
    "n_orig = df_y2.shape[0]\n",
    "n_na = df_y2['release'].isna().sum()\n",
    "df_y2 = df_y2.dropna(subset=['release'])\n",
    "print(f'y2: Dropped {n_na} entries of {n_orig}, {n_orig - n_na} entries left.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Target transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df_y1['popularity']\n",
    "y1 = y1.to_numpy()\n",
    "np.savetxt('featsets/y1.csv', y1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = df_y2['release']\n",
    "y2 = y2.to_numpy()\n",
    "np.savetxt('featsets/y2.csv', y1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Featsets\n",
    "Different steps and kinds of preprocessing are combined to produce featuresets.\n",
    "https://towardsdatascience.com/feature-selection-and-dimensionality-reduction-f488d1a035de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Featset:\n",
    "    def __init__(self, X, name):\n",
    "        self.X = X\n",
    "        self.name = name\n",
    "\n",
    "        self.timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        self.outlier_removal = 'None'\n",
    "        self.scaling_ft = 'None'\n",
    "        self.dimension_reduction = 'None'\n",
    "\n",
    "    def remove_stde(self):\n",
    "        pass\n",
    "\n",
    "    def remove_lof(self):\n",
    "        clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "        y_pred = clf.fit_predict(self.X)\n",
    "        X_scores = clf.negative_outlier_factor_\n",
    "        pass\n",
    "\n",
    "    def remove(self, type):\n",
    "        if type == \"stde\":\n",
    "            self.stde()\n",
    "            self.outlier = 'stde'\n",
    "        elif type == \"lof\":\n",
    "            self.lof()\n",
    "            self.outlier = 'lof'\n",
    "        else:\n",
    "            print(\"Not available\")\n",
    "            pass\n",
    "\n",
    "    def scaling(self, type):\n",
    "        pass\n",
    "    \n",
    "    def reduce_pca(self, type):\n",
    "        pass\n",
    "\n",
    "    def reduce(self, type):\n",
    "        if type == \"pca\":\n",
    "            self.reduce_pca()\n",
    "            self.outlier = 'stde'\n",
    "        else:\n",
    "            print(\"Not available\")\n",
    "            pass\n",
    "\n",
    "    def save(self):\n",
    "        np.savetxt(f'featsets/{self.name}.csv', self.X, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_y1.drop(columns=['popularity']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'X1/00_first_try'\n",
    "fts = Featset(X1, name)\n",
    "fts.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df_y2.drop(columns=['release']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'X2/00_first_try'\n",
    "fts = Featset(X2, name)\n",
    "fts.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdda72482b74b36a8cd983d5e1bcef53bc8833d37b4bc186fc16d6768393ee16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
