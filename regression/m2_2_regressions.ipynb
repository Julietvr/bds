{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1 - popularity: models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "sns.set_theme()\n",
    "# Show plots\n",
    "viz = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feats():\n",
    "    \"\"\"\n",
    "    Each feature has a first name, optionally a second name, a statistic and a number.\n",
    "    This class allows to group feautures according to these aspects or combinations of these aspects.\n",
    "    Each method produces a list of feature names or a list of lists of feature names.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv):\n",
    "        self.fts = pd.read_csv(csv, dtype={'n':\"string\"})\n",
    "        self.fts = self.fts.fillna('')\n",
    "\n",
    "    def format(self, select):\n",
    "        return select.apply(lambda x: '_'.join(x).replace('__', '_'), axis=1).tolist()\n",
    "\n",
    "    def all(self):\n",
    "        select = self.fts.copy()\n",
    "        return self.format(select)\n",
    "\n",
    "    def first(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['n']=='01']\n",
    "        return self.format(select)\n",
    "\n",
    "    def mean(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='mean']\n",
    "        return self.format(select)\n",
    "    \n",
    "    def std(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='std']\n",
    "        return self.format(select)\n",
    "\n",
    "    def kurtosis(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['stat']=='kurtosis']\n",
    "        return self.format(select)\n",
    "    \n",
    "    def chroma(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['name1']=='chroma']\n",
    "        return self.format(select)\n",
    "\n",
    "    def mfcc(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['name1']=='mfcc']\n",
    "        return self.format(select)\n",
    "\n",
    "    def tonnetz(self):\n",
    "        select = self.fts.copy()\n",
    "        select = select.loc[select['name1']=='tonnetz']\n",
    "        return self.format(select)\n",
    "\n",
    "fts = Feats('features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fold\n",
    "df_train = pd.read_csv('data/fold/f2_train.csv',  parse_dates=['release'])\n",
    "df_train = df_train.drop(columns=['release'])\n",
    "df_test = pd.read_csv('data/fold/f2_test.csv',  parse_dates=['release'])\n",
    "df_test = df_test.drop(columns=['release'])\n",
    "print(f'train set: {df_train.shape[0]:,} entries, test set: {df_test.shape[0]:,} entries, total: {df_train.shape[0]+df_test.shape[0]:,} entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA and zero values train\n",
    "n_orig = df_train.shape[0]\n",
    "n_na = df_train['popularity'].isna().sum()\n",
    "df_train = df_train.dropna(subset=['popularity'])\n",
    "n_zero =df_train.loc[df_train['popularity']==0].shape[0]\n",
    "df_train = df_train.loc[df_train['popularity']>0]\n",
    "print(f'Train set: Dropped {n_na} NA entries and {n_zero} zero entries of {n_orig}, {df_train.shape[0]} entries left.')\n",
    "\n",
    "# Drop NA and zero values test\n",
    "n_orig = df_test.shape[0]\n",
    "n_na = df_test['popularity'].isna().sum()\n",
    "df_test = df_test.dropna(subset=['popularity'])\n",
    "n_zero =df_test.loc[df_test['popularity']==0].shape[0]\n",
    "df_test = df_test.loc[df_test['popularity']>0]\n",
    "print(f'Test set: Dropped {n_na} NA entries and {n_zero} zero entries of {n_orig}, {df_test.shape[0]} entries left.')\n",
    "\n",
    "# Scale X train and test\n",
    "X_train = df_train.drop(columns=['popularity'])\n",
    "X_test = df_test.drop(columns=['popularity'])\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train, columns=fts.all())\n",
    "X_test = pd.DataFrame(X_test, columns=fts.all())\n",
    "print('')\n",
    "print(f'Scaled train X:\\n\\tmean: {X_train.mean().tolist()[:5]}...\\n\\tstd: {X_train.std().tolist()[:5]}...')\n",
    "print(f'Scaled test X:\\n\\tmean: {X_test.mean().tolist()[:5]}...\\n\\tstd: {X_test.std().tolist()[:5]}...')\n",
    "\n",
    "# Transform y train and test\n",
    "y_train_before = df_train['popularity']\n",
    "y_train = stats.boxcox(y_train_before)[0]\n",
    "y_train = pd.Series(y_train)\n",
    "y_test_before = df_test['popularity']\n",
    "y_test = stats.boxcox(y_test_before)[0]\n",
    "y_test = pd.Series(y_test)\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "ax1 = sns.histplot(x=y_train_before, kde=True, ax=axs[0])\n",
    "ax1.set(title=\"Distribution popularity\")\n",
    "ax2 = sns.histplot(x=y_train, kde=True, ax=axs[1])\n",
    "ax2.set(title=\"Distribution boxcox transformed popularity\")\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2_train_bm = round(model.score(X_train, y_train), 6)\n",
    "r2_test_bm = round(metrics.r2_score(y_test, y_pred), 6)\n",
    "\n",
    "print(f'Benchmark: Train R2 for all features: {r2_train_bm}, Test R2 for all features: {r2_test_bm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'linear_regression'\n",
    "\n",
    "X_train_fts = X_train[fts.all()]\n",
    "X_test_fts = X_test[fts.all()]\n",
    "\n",
    "model = LinearRegression().fit(X_train_fts, y_train)\n",
    "y_pred = model.predict(X_test_fts)\n",
    "\n",
    "scores[name] = {\n",
    "    'R2_train': round(model.score(X_train_fts, y_train), 6),\n",
    "    'R2_test': round(metrics.r2_score(y_test, y_pred), 6),\n",
    "    'MSE_test': round(metrics.mean_squared_error(y_test, y_pred), 6),\n",
    "    'MAE_test': round(metrics.mean_absolute_error(y_test, y_pred), 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'elastic_net'\n",
    "\n",
    "X_train_fts = X_train[fts.all()]\n",
    "X_test_fts = X_test[fts.all()]\n",
    "\n",
    "model = ElasticNet().fit(X_train_fts, y_train)\n",
    "y_pred = model.predict(X_test_fts)\n",
    "\n",
    "scores[name] = {\n",
    "    'R2_train': round(model.score(X_train_fts, y_train), 6),\n",
    "    'R2_test': round(metrics.r2_score(y_test, y_pred), 6),\n",
    "    'MSE_test': round(metrics.mean_squared_error(y_test, y_pred), 6),\n",
    "    'MAE_test': round(metrics.mean_absolute_error(y_test, y_pred), 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'poly_linear_regression_mean_fts'\n",
    "\n",
    "X_train_fts = X_train[fts.mean()]\n",
    "X_test_fts = X_test[fts.mean()]\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_fts = poly.fit_transform(X_train_fts)\n",
    "X_test_fts = poly.fit_transform(X_test_fts)\n",
    "\n",
    "model = LinearRegression().fit(X_train_fts, y_train)\n",
    "y_pred = model.predict(X_test_fts)\n",
    "\n",
    "scores[name] = {\n",
    "    'R2_train': round(model.score(X_train_fts, y_train), 6),\n",
    "    'R2_test': round(metrics.r2_score(y_test, y_pred), 6),\n",
    "    'MSE_test': round(metrics.mean_squared_error(y_test, y_pred), 6),\n",
    "    'MAE_test': round(metrics.mean_absolute_error(y_test, y_pred), 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR - support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'svr_10%_sub'\n",
    "\n",
    "X_train_fts = X_train[fts.all()]\n",
    "X_test_fts = X_test[fts.all()]\n",
    "idx = X_train_fts.sample(frac=0.1).index\n",
    "X_train_fts_sub = X_train_fts.iloc[idx]\n",
    "y_train_sub = y_train[idx]\n",
    "\n",
    "model = SVR().fit(X_train_fts_sub, y_train_sub)\n",
    "y_pred = model.predict(X_test_fts)\n",
    "\n",
    "scores[name] = {\n",
    "    'R2_train': round(model.score(X_train_fts_sub, y_train_sub), 6),\n",
    "    'R2_test': round(metrics.r2_score(y_test, y_pred), 6),\n",
    "    'MSE_test': round(metrics.mean_squared_error(y_test, y_pred), 6),\n",
    "    'MAE_test': round(metrics.mean_absolute_error(y_test, y_pred), 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-neighbors regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'k-neighbors'\n",
    "\n",
    "X_train_fts = X_train[fts.all()]\n",
    "X_test_fts = X_test[fts.all()]\n",
    "\n",
    "model = KNeighborsRegressor().fit(X_train_fts, y_train)\n",
    "y_pred = model.predict(X_test_fts)\n",
    "\n",
    "scores[name] = {\n",
    "    'R2_train': round(model.score(X_train_fts, y_train), 6),\n",
    "    'R2_test': round(metrics.r2_score(y_test, y_pred), 6),\n",
    "    'MSE_test': round(metrics.mean_squared_error(y_test, y_pred), 6),\n",
    "    'MAE_test': round(metrics.mean_absolute_error(y_test, y_pred), 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame.from_dict(scores, orient='index')\n",
    "df_scores.style\\\n",
    "    .highlight_max(color='green', axis=0)\\\n",
    "    .highlight_min(color='red', axis=0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdda72482b74b36a8cd983d5e1bcef53bc8833d37b4bc186fc16d6768393ee16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
